{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dd9479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc6d8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All augmented images have been created and saved.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Define the input and output directories\n",
    "input_dir = 'dataset'\n",
    "output_dir = 'C:/Users/vedpr/Downloads/Orientation_Assignment/'\n",
    "train_dir_horizontal = os.path.join(output_dir, 'train/horizontal')\n",
    "train_dir_vertical = os.path.join(output_dir, 'train/vertical')\n",
    "validation_dir_horizontal = os.path.join(output_dir, 'validation/horizontal')\n",
    "validation_dir_vertical = os.path.join(output_dir, 'validation/vertical')\n",
    "\n",
    "# Create output directories if they do not exist\n",
    "os.makedirs(train_dir_horizontal, exist_ok=True)\n",
    "os.makedirs(train_dir_vertical, exist_ok=True)\n",
    "os.makedirs(validation_dir_horizontal, exist_ok=True)\n",
    "os.makedirs(validation_dir_vertical, exist_ok=True)\n",
    "\n",
    "# Function to mirror the top half of the image\n",
    "def mirror_top_half(image):\n",
    "    width, height = image.size\n",
    "    top_half = image.crop((0, 0, width, height // 2))\n",
    "    mirrored_top_half = top_half.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    new_image = Image.new('RGB', (width, height))\n",
    "    new_image.paste(mirrored_top_half, (0, 0))\n",
    "    new_image.paste(top_half, (0, height // 2))\n",
    "    return new_image\n",
    "\n",
    "# Function to mirror the bottom half of the image\n",
    "def mirror_bottom_half(image):\n",
    "    width, height = image.size\n",
    "    bottom_half = image.crop((0, height // 2, width, height))\n",
    "    mirrored_bottom_half = bottom_half.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    new_image = Image.new('RGB', (width, height))\n",
    "    new_image.paste(mirrored_bottom_half, (0, height // 2))\n",
    "    new_image.paste(bottom_half, (0, 0))\n",
    "    return new_image\n",
    "\n",
    "# Function to mirror the left half of the image\n",
    "def mirror_left_half(image):\n",
    "    width, height = image.size\n",
    "    left_half = image.crop((0, 0, width // 2, height))\n",
    "    mirrored_left_half = left_half.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    new_image = Image.new('RGB', (width, height))\n",
    "    new_image.paste(mirrored_left_half, (width // 2, 0))\n",
    "    new_image.paste(left_half, (0, 0))\n",
    "    return new_image\n",
    "\n",
    "# Function to mirror the right half of the image\n",
    "def mirror_right_half(image):\n",
    "    width, height = image.size\n",
    "    right_half = image.crop((width // 2, 0, width, height))\n",
    "    mirrored_right_half = right_half.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    new_image = Image.new('RGB', (width, height))\n",
    "    new_image.paste(mirrored_right_half, (0, 0))\n",
    "    new_image.paste(right_half, (width // 2, 0))\n",
    "    return new_image\n",
    "\n",
    "# Function to process each image and create four augmented images\n",
    "def process_images(input_dir, train_dir_horizontal, train_dir_vertical, validation_dir_horizontal, validation_dir_vertical):\n",
    "    all_images = [f for f in os.listdir(input_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    random.shuffle(all_images)\n",
    "    \n",
    "    split_index = int(len(all_images) * 0.8)\n",
    "    train_images = all_images[:split_index]\n",
    "    validation_images = all_images[split_index:]\n",
    "    \n",
    "    for i, filename in enumerate(all_images):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Create the four augmented images\n",
    "        mirrored_top_image = mirror_top_half(image)\n",
    "        mirrored_bottom_image = mirror_bottom_half(image)\n",
    "        mirrored_left_image = mirror_left_half(image)\n",
    "        mirrored_right_image = mirror_right_half(image)\n",
    "\n",
    "        # Determine if the image should go to train or validation set\n",
    "        if filename in train_images:\n",
    "            base_dir_horizontal = train_dir_horizontal\n",
    "            base_dir_vertical = train_dir_vertical\n",
    "        else:\n",
    "            base_dir_horizontal = validation_dir_horizontal\n",
    "            base_dir_vertical = validation_dir_vertical\n",
    "\n",
    "        # Save the augmented images in respective directories\n",
    "        base_filename = os.path.splitext(filename)[0]\n",
    "        mirrored_top_image.save(os.path.join(base_dir_horizontal, f'{base_filename}_mirrored_top.png'))\n",
    "        mirrored_bottom_image.save(os.path.join(base_dir_horizontal, f'{base_filename}_mirrored_bottom.png'))\n",
    "        mirrored_left_image.save(os.path.join(base_dir_vertical, f'{base_filename}_mirrored_left.png'))\n",
    "        mirrored_right_image.save(os.path.join(base_dir_vertical, f'{base_filename}_mirrored_right.png'))\n",
    "\n",
    "    print(\"All augmented images have been created and saved.\")\n",
    "\n",
    "# Run the function\n",
    "process_images(input_dir, train_dir_horizontal, train_dir_vertical, validation_dir_horizontal, validation_dir_vertical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89cf8b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.7049 - accuracy: 0.5250 - val_loss: 0.6915 - val_accuracy: 0.5156\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 8s 785ms/step - loss: 0.6947 - accuracy: 0.4969 - val_loss: 0.6900 - val_accuracy: 0.6406\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 8s 775ms/step - loss: 0.6921 - accuracy: 0.5063 - val_loss: 0.6858 - val_accuracy: 0.7656\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 8s 797ms/step - loss: 0.6711 - accuracy: 0.5969 - val_loss: 0.6200 - val_accuracy: 0.6562\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 8s 783ms/step - loss: 0.6205 - accuracy: 0.6562 - val_loss: 0.4659 - val_accuracy: 0.7812\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 8s 824ms/step - loss: 0.5990 - accuracy: 0.6781 - val_loss: 0.4389 - val_accuracy: 0.7812\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 7s 673ms/step - loss: 0.5250 - accuracy: 0.7219 - val_loss: 0.4489 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 7s 651ms/step - loss: 0.4887 - accuracy: 0.7688 - val_loss: 0.3532 - val_accuracy: 0.8594\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 7s 645ms/step - loss: 0.5188 - accuracy: 0.7531 - val_loss: 0.4305 - val_accuracy: 0.8125\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 7s 649ms/step - loss: 0.5284 - accuracy: 0.7094 - val_loss: 0.3060 - val_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 7s 646ms/step - loss: 0.4668 - accuracy: 0.7750 - val_loss: 0.3223 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 7s 658ms/step - loss: 0.4280 - accuracy: 0.7969 - val_loss: 0.3370 - val_accuracy: 0.8906\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 7s 664ms/step - loss: 0.4718 - accuracy: 0.7781 - val_loss: 0.3699 - val_accuracy: 0.8281\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 7s 653ms/step - loss: 0.4285 - accuracy: 0.8062 - val_loss: 0.3477 - val_accuracy: 0.8594\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 7s 662ms/step - loss: 0.4192 - accuracy: 0.8000 - val_loss: 0.3172 - val_accuracy: 0.8906\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 7s 708ms/step - loss: 0.3825 - accuracy: 0.8313 - val_loss: 0.4071 - val_accuracy: 0.8125\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 7s 678ms/step - loss: 0.3785 - accuracy: 0.8062 - val_loss: 0.3631 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 7s 658ms/step - loss: 0.3588 - accuracy: 0.8313 - val_loss: 0.4133 - val_accuracy: 0.8125\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 7s 649ms/step - loss: 0.4497 - accuracy: 0.7969 - val_loss: 0.3285 - val_accuracy: 0.9219\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 7s 657ms/step - loss: 0.4078 - accuracy: 0.8031 - val_loss: 0.4140 - val_accuracy: 0.8281\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.3732 - accuracy: 0.8375\n",
      "Validation accuracy: 83.75%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define directories\n",
    "base_dir ='C:/Users/vedpr/Downloads/Orientation_Assignment/'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data normalization for validation\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('augmented_image_classifier.h5')\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61b9afde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 96ms/step\n",
      "The image is classified as: vertical\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def classify_image(image_path, model_path='augmented_image_classifier.h5'):\n",
    "    # Load the trained model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    \n",
    "    # Predict the class probabilities\n",
    "    class_probabilities = model.predict(img_array)[0]\n",
    "    \n",
    "    # Determine the predicted class based on probabilities\n",
    "    if class_probabilities[0] <0.5:\n",
    "        return 'horizontal'\n",
    "    else:\n",
    "        return 'vertical'\n",
    "\n",
    "# Example usage\n",
    "image_path = r'C:\\Users\\vedpr\\Downloads\\Orientation_Assignment\\validation\\vertical\\airplane_0005_mirrored_left.png'\n",
    "predicted_class = classify_image(image_path)\n",
    "print(f\"The image is classified as: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b098779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "The image is classified as: horizontal\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path = r'C:\\Users\\vedpr\\Downloads\\Orientation_Assignment\\validation\\horizontal\\airplane_0005_mirrored_bottom.png'\n",
    "predicted_class = classify_image(image_path)\n",
    "print(f\"The image is classified as: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55770d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
